{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf720a90",
   "metadata": {},
   "source": [
    "# CNN ile Fruits 360 Veri Setini Siniflandiralim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab2d6af",
   "metadata": {},
   "source": [
    "### Gerekli kutuphanelerimiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28563fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Conv2D, MaxPooling2D, Flatten, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.image_utils import load_img, img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e5e600",
   "metadata": {},
   "source": [
    "### Egitim Veri Setimizin Bilgisayardaki Yolu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59b6a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'C:/Users/mehmet/Desktop/Fruits 360/fruits-360_dataset/fruits-360/Training/'\n",
    "test_path = 'C:/Users/mehmet/Desktop/Fruits 360/fruits-360_dataset/fruits-360/Test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f09453",
   "metadata": {},
   "source": [
    "### Ornek Resim yukleyelim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e929958",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img(train_path + 'Apple Braeburn/0_100.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a00007d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2120a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_test = load_img(test_path + 'Apple Braeburn/69_100.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce32df62",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_test)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe60ada9",
   "metadata": {},
   "source": [
    "### Resmimizin Boyutlari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd88c642",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = img_to_array(img)\n",
    "x.shape # Width, Height, 3D Resim old. belli eden derinlik"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3838bad0",
   "metadata": {},
   "source": [
    "### Kac tane output old. ogrenelim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae360fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = glob(train_path + '/*')\n",
    "number_of_class = len(class_name)\n",
    "number_of_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11008677",
   "metadata": {},
   "source": [
    "## Modelimizi Olusturalim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31def84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(100, 100, 3))) # Filtre Sayisi, Filtre Boyutu, Resmin Boyutlari\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) # Havuzlama Katmani Boyutlari\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=1024))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(units=number_of_class))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af1765a",
   "metadata": {},
   "source": [
    "### Modelimizi Derleyelim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd469923",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61301bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 # Tek bir seferde 32 resim ile egitilsin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65788e3",
   "metadata": {},
   "source": [
    "## Train ve Test veri setlerimizi belirleyelim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3da0475",
   "metadata": {},
   "source": [
    "#### Her bir kategoride 400 üstü resim old. gore bu resmi cogaltmak icin Data Augmentation/ImageDataGenerator/Resimleri Coklayalim."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec1c1c0",
   "metadata": {},
   "source": [
    "### Image Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8323e71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, # scaling(0-1) arasina cek\n",
    "                                  shear_range=0.3, # resmi belirttigimiz deger kadar dondur\n",
    "                                  horizontal_flip=True, # yatay bir sekilde dondur\n",
    "                                  zoom_range=0.3, # belirlenen deger kadar yakinlastirir\n",
    "                                  )\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) # test edecegimiz resimleri scale etsek yeter aksi halde resim bozulursa pek dogru sonuclar elde edemeyiz\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(directory=train_path, # Siniflandirilmis Resimlerimizin bulundugu Ana Dizinimiz\n",
    "                                                    target_size=(100, 100), # Resimlerimizin Boyutlari\n",
    "                                                    batch_size=batch_size, # Bir seferde alinacak resim miktari\n",
    "                                                    color_mode='rgb', # Resimlerimizin formati\n",
    "                                                    class_mode='categorical', # birden fazla sinifimizin old. belirttik\n",
    "                                                   )\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(directory=test_path,\n",
    "                                                 target_size=(100, 100),\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 color_mode='rgb',\n",
    "                                                 class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af29ee9",
   "metadata": {},
   "source": [
    "## Modelimizi Egitelim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11be053e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch= 1600 // batch_size, # bir epoch boyunca 50 defa verimizi train edelim\n",
    "                              # bizim baslangicta 400 resmimiz var bunu batch_size'e bolunce 1 epoch'da 12 defa train eder.\n",
    "                              # Peki bu diger resimler nerden geldi?\n",
    "                              # 50*32=1600 1200 civari resim ImageDataGenerator'den geliyor.\n",
    "                              epochs=100,\n",
    "                              validation_data=test_generator, # validation_generator\n",
    "                              validation_steps=800\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb3ec98",
   "metadata": {},
   "source": [
    "### Modelimizi Degerlendirelim - Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3031ec87",
   "metadata": {},
   "source": [
    "#### Modeli Kaydedelim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ca798a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('deneme_h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791e008e",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be55eac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eea8250",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='Train Loss Value')\n",
    "plt.plot(history.history['val_loss'], label='Train Validation Loss Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc86c86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Train Accuracy Value')\n",
    "plt.plot(history.history['val_accuracy'], label='Train Validation Accuracy Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d9d834",
   "metadata": {},
   "source": [
    "### History degerlerini json formatinda kaydedelim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be27a082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94286174",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cnn_fruits-360_hist.json', 'w') as f:\n",
    "    json.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178f9744",
   "metadata": {},
   "source": [
    "#### History Degerlerini Yukleyelim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4c7836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8bc8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open('cnn_fruits-360_hist.json', 'r', encoding='utf-8') as f:\n",
    "    h = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2357bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3f040c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h['loss'], label='Train Loss Value')\n",
    "plt.plot(h['val_loss'], label='Train Validation Loss Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9550e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h['accuracy'], label='Train Accuracy Value')\n",
    "plt.plot(h['val_accuracy'], label='Train Validation Accuracy Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9b1d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
